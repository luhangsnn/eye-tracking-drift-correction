{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18fd8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import drift_algorithms as algo\n",
    "import numpy as np \n",
    "import json\n",
    "import emip_toolkit as EMTK\n",
    "import pandas as pd\n",
    "import correction\n",
    "import tensorflow as tf\n",
    "import prep_GB_img as prepgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378e3c1",
   "metadata": {},
   "source": [
    "## RS81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bbcdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file_names = [\"S_8152_S1_TEX.json\", \"S_8063_S1_TEX.json\",\n",
    "              \"S_8107_S1_TEX.json\", \"S_8331_S1_TEX.json\"]\n",
    "clean_file_names = [\"S_8152_S1_TEX_CORRECTED.json\", \"S_8063_S1_TEX_CORRECTED.json\",\n",
    "              \"S_8107_S1_TEX_CORRECTED.json\", \"S_8331_S1_TEX_CORRECTED.json\"]\n",
    "image_path = \"Golden_Set/R8S1/\"\n",
    "image = \"TEX_R8S1_bg.png\"\n",
    "file_path = \"Golden_Set/R8S1/\"\n",
    "txt_file_name = \"TEX_R8S1_text.txt\"\n",
    "file_path = \"Golden_Set/R8S1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "132e2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = EMTK.find_aoi(image, image_path, level=\"sub-line\")\n",
    "aois_with_tokens = EMTK.add_tokens_to_AOIs(file_path,txt_file_name, aoi)\n",
    "line_ys = correction.find_lines_Y(aois_with_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18112f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_centers = correction.find_word_centers(aoi)\n",
    "word_centers = np.array(word_centers.copy(), dtype=int)\n",
    "\n",
    "duration_word_centers = correction.find_word_centers_and_duration(aois_with_tokens)\n",
    "duration_word_centers = np.array(duration_word_centers.copy(), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86fa2cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"saved_models_mix_ayn/model_tl.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a98034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [[], [], [], [], [], [], [], [], []]\n",
    "\n",
    "for i in range(4):\n",
    "    with open(file_path + dirty_file_names[i]) as f:\n",
    "       dirty_dict = json.load(f)\n",
    "    \n",
    "    #dirty dataframe\n",
    "    dirty_df = pd.DataFrame.from_dict(dirty_dict)\n",
    "    #Transpose the dirty\n",
    "    dirty_df = pd.DataFrame.transpose(dirty_df)\n",
    "    #convert to numpy\n",
    "    dirty_np = np.array(dirty_df)\n",
    "\n",
    "   # clean, corrected data\n",
    "    with open(file_path + clean_file_names[i]) as f:\n",
    "       clean_dict = json.load(f)\n",
    "\n",
    "    clean_fixs = clean_dict[\"fixations_data\"]\n",
    "    clean_df = pd.DataFrame.from_dict(clean_fixs)\n",
    "    clean_df = pd.DataFrame.transpose(clean_df)\n",
    "    clean_np = np.array(clean_df)\n",
    "    \n",
    "    #run the algorithms\n",
    "    \n",
    "    #attach\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    correction_p = algo.attach(np_array, line_ys)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, correction_p)\n",
    "    acc[0].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)\n",
    "    \n",
    "    #chain\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    correction_p = algo.chain(np_array, line_ys)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, correction_p)\n",
    "    acc[1].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)    \n",
    "    \n",
    "    #cluster\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    correction_p = algo.cluster(np_array, line_ys)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, correction_p)\n",
    "    acc[2].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)\n",
    "    \n",
    "    #merge\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    correction_p = algo.merge(np_array, line_ys, y_thresh = 50)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, correction_p)\n",
    "    acc[3].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)\n",
    "    \n",
    "    #regress\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    correction_p = algo.regress(np_array, line_ys)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, correction_p)\n",
    "    acc[4].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)\n",
    "\n",
    "    #segment\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    correction_p = algo.segment(np_array, line_ys)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, correction_p)\n",
    "    acc[5].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)\n",
    "\n",
    "    #split\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    correction_p = algo.split(np_array, line_ys)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, correction_p)\n",
    "    acc[6].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)\n",
    "    \n",
    "    #stretch\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    correction_p = algo.stretch(np_array, line_ys)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, correction_p)\n",
    "    acc[7].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)\n",
    "    \n",
    "    # warp\n",
    "    np_array = np.array(dirty_np.copy(), dtype=int)\n",
    "    durations = np.delete(np_array, 0, 1)\n",
    "    durations = np.delete(durations, 0, 1)\n",
    "    np_array = np.delete(np_array, 2, 1)\n",
    "    warp_correction = algo.warp(np_array, word_centers)\n",
    "    percentage, match_list = correction.correction_quality(aoi, clean_np, warp_correction)\n",
    "    acc[8].append(percentage)\n",
    "   #  correction.draw_correction(image_path+image, correction_p, match_list)\n",
    "\n",
    "   # with classifier\n",
    "    np_array = np.array(dirty_np.copy())\n",
    "    predicted_error = correction.predict_error(\n",
    "                image, \n",
    "                np_array, \n",
    "                aois_with_tokens, \n",
    "                input_x, \n",
    "                input_y, \n",
    "                model)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "615e1208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.788546255506608, 0.33649289099526064, 0.4423076923076923, 0.6172248803827751], [0.8193832599118943, 0.3412322274881517, 0.5048076923076923, 0.6220095693779905], [0.29955947136563876, 0.3791469194312796, 0.7211538461538461, 0.2583732057416268], [0.09251101321585903, 0.2037914691943128, 0.10576923076923077, 0.11961722488038277], [0.788546255506608, 0.47393364928909953, 0.5625, 0.5502392344497608], [0.02643171806167401, 0.4075829383886256, 0.6826923076923077, 0.2679425837320574], [0.8458149779735683, 0.35071090047393366, 0.4326923076923077, 0.5358851674641149], [0.7929515418502202, 0.009478672985781991, 0.6730769230769231, 0.22966507177033493], [0.5330396475770925, 0.15165876777251186, 0.6490384615384616, 0.5645933014354066]]\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
